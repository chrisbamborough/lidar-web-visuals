# LiDAR Web Visuals (Record3D â†’ WebRTC â†’ Three.js)

Live, browser-based visuals using iPhone/iPad LiDAR via the **Record3D** app.  
This repo uses **Vite** + **Three.js (ES Modules)** and a â€œsketch-per-folderâ€ workflow for fast creative iterations.

## âœ¨ What you can do

- Connect directly to the iPhoneâ€™s **Wi-Fi WebRTC** stream (no server needed)
- Decode **HSV-encoded depth** and render a **point cloud** with Three.js
- Create a new visual by copying a sketch folder and editing `main.js`

---

## ğŸ§± Project structure

lidar-web-visuals/
â”œâ”€ package.json
â”œâ”€ vite.config.js
â”œâ”€ public/
â”‚ â””â”€ assets/ # optional shared assets
â””â”€ sketches/
â”œâ”€ lidar-basic/
â”‚ â”œâ”€ index.html
â”‚ â”œâ”€ main.js
â”‚ â””â”€ style.css
â””â”€ <your-next-sketch>/
â”œâ”€ index.html
â”œâ”€ main.js
â””â”€ style.css

Each folder in `sketches/` is a self-contained â€œsketchâ€ (like p5/Processing).

---

## ğŸš€ Quick start

1. **Install**

```bash
npm install
```

2. Run the dev server

bash
Copy code
npm run dev
Vite prints a URL (e.g. http://localhost:5173/).

Open a sketch
Visit http://localhost:5173/sketches/lidar-basic/ (or any other sketch folder).

On your iPhone/iPad

Open the Record3D app â†’ Wi-Fi Streaming

Turn the red toggle ON and leave the screen awake

Note the IP, e.g. http://192.168.86.28

Connect from the sketch
In the webpage input, enter the phone URL (e.g. http://192.168.86.28) and click Connect.
You should see a live point cloud (adjust Step and Depth as needed).

Use http:// for both the page and the phone. Opening the page on https:// will block http://phone-ip (mixed content).

â• Create a new sketch
Copy an existing one and rename:

bash
Copy code
cp -r sketches/lidar-basic sketches/my-new-idea
Open sketches/my-new-idea/ and edit main.js.
Then visit http://localhost:5173/sketches/my-new-idea/.

âš™ï¸ Vite configuration
vite.config.js is set to treat each sketches/<name>/index.html as an entry point and opens lidar-basic by default on npm run dev.

ğŸ› ï¸ Useful scripts
dev â€“ start the dev server:

bash
Copy code
npm run dev
build â€“ make a production build (outputs to dist/):

bash
Copy code
npm run build
Deploy dist/ to GitHub Pages / Vercel / Netlify.

ğŸ”Œ Record3D endpoints (Wi-Fi)
The browser uses these endpoints directly on the phone:

GET /metadata â†’ intrinsics and metadata

GET /getOffer â†’ returns { type: "offer", sdp: "..." }

POST /answer â†’ with body { type: "answer", data: "<your SDP>" }

Close any opened browser demo on the phone/desktop: only one WebRTC peer can connect at a time.

ğŸ§ª Troubleshooting
â€œFailed to fetch / JSON parse errorâ€
You probably typed localhost or left the field blank; use the phoneâ€™s IP URL, e.g. http://192.168.x.x.

Nothing happens / no video
Make sure the Record3D red toggle is ON, the app is foregrounded, and the page is served over http:// (not https).

IP changed
Re-check the IP on the phoneâ€™s Wi-Fi Streaming screen and reconnect.

Performance
Increase â€œStepâ€ to downsample the point cloud. For big gains, move decoding & projection to GPU shaders (see ideas below).

ğŸ§  Ideas & extensions
Shader pipeline: hueâ†’depth in a fragment shader, XYZ in a vertex shader (huge speed-up)

OrbitControls: use three/examples/jsm/controls/OrbitControls.js

Recording: capture the WebGL canvas with MediaRecorder

Post-processing: add bloom, DOF, CRT, etc. via EffectComposer

Gallery: auto-index all sketches at / with thumbnails
